# Backlink Templates

Use these short posts to create external backlinks to the repo.

## GitHub Readme Link Block
llamatelemetry is a CUDA-first OpenTelemetry Python SDK for LLM inference observability and GPU telemetry with llama.cpp GGUF and NCCL multi-GPU workflows.
Repo: https://github.com/llamatelemetry/llamatelemetry
Docs: https://llamatelemetry.github.io/llamatelemetry/

## Hugging Face Model Card Snippet
This project integrates with llamatelemetry for OpenTelemetry tracing and GPU metrics.
Repo: https://github.com/llamatelemetry/llamatelemetry
Docs: https://llamatelemetry.github.io/llamatelemetry/

## Reddit Post (r/MachineLearning or r/LocalLLaMA)
Title: llamatelemetry - CUDA-first OpenTelemetry SDK for LLM inference observability
Body:
I released llamatelemetry (v0.1.0), a CUDA-first OpenTelemetry Python SDK for LLM inference observability and GPU telemetry. It targets llama.cpp GGUF workflows and NCCL multi-GPU setups, with OTLP-compatible traces and metrics.
Repo: https://github.com/llamatelemetry/llamatelemetry
Docs: https://llamatelemetry.github.io/llamatelemetry/

## Hacker News Post
Title: llamatelemetry â€“ CUDA-first OpenTelemetry SDK for LLM inference observability
Text:
llamatelemetry (v0.1.0) is a CUDA-first OpenTelemetry Python SDK for LLM inference observability and GPU telemetry. It targets llama.cpp GGUF inference and NCCL multi-GPU workflows, exporting OTLP traces and metrics.
Repo: https://github.com/llamatelemetry/llamatelemetry
Docs: https://llamatelemetry.github.io/llamatelemetry/

## LinkedIn Post
llamatelemetry v0.1.0 is live. It is a CUDA-first OpenTelemetry Python SDK for LLM inference observability and GPU telemetry with llama.cpp GGUF and NCCL multi-GPU workflows.
Repo: https://github.com/llamatelemetry/llamatelemetry
Docs: https://llamatelemetry.github.io/llamatelemetry/
